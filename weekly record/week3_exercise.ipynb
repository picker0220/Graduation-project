
Week 1
图片基础处理
import cv2#opencv读取的格式是BGR
import matplotlib.pyplot as plt
import numpy as np
%matplotlib inline

img = cv2.imread('cat.png')#图像的读取
img
array([[[125, 127, 129],
        [140, 142, 144],
        [146, 152, 158],
        ...,
        [151, 155, 157],
        [149, 154, 155],
        [153, 155, 157]],

       [[ 67,  70,  75],
        [116, 119, 124],
        [109, 116, 125],
        ...,
        [165, 173, 179],
        [163, 170, 176],
        [162, 168, 174]],

       [[ 89,  93,  97],
        [109, 112, 116],
        [107, 114, 122],
        ...,
        [166, 174, 180],
        [167, 175, 181],
        [164, 169, 175]],

       ...,

       [[ 82,  95, 106],
        [127, 141, 151],
        [154, 172, 184],
        ...,
        [152, 162, 168],
        [175, 185, 191],
        [198, 208, 214]],

       [[170, 184, 194],
        [173, 186, 196],
        [150, 168, 180],
        ...,
        [197, 207, 213],
        [193, 203, 209],
        [194, 204, 210]],

       [[133, 147, 157],
        [153, 166, 177],
        [151, 169, 181],
        ...,
        [190, 200, 206],
        [175, 185, 191],
        [131, 142, 147]]], dtype=uint8)
cv2.imshow('image',img)
cv2.waitKey(5000)#图片展示的时间长度，单位ms
cv2.destroyAllWindows()#当等待时间为0时，键盘反馈关闭窗口。不为0时到时间自动关闭窗口。
def cv_show(name,img):
    cv2.imshow('image',img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
cv_show('image',img)
img.shape#输出结果为：（h,w,c），也就是（高度，宽度，维度<BGR>）
(413, 499, 3)
img = cv2.imread('cat.png',cv2.IMREAD_GRAYSCALE)#对图片进行灰度处理
# img
img.shape
(413, 499)
cv_show('image',img)
cv2.imwrite('cat_gray.png',img)#图片保存
True
视频处理
import cv2
import matplotlib.pyplot as plt
import numpy as np
vc = cv2.VideoCapture('test_video.mp4')
# vc.release()
# cv2.destroyAllWindows()
if vc.isOpened():
    open, frame = vc.read()
else:
    open = False
# frame.shape
# frame = cv2.resize(frame,(270,480))检测截取图片大小并调整以适应电脑屏幕播放
while open:
    ret, frame = vc.read()#ret：是否读到了一帧图片（True or False）  frame：具体图片
    if frame is None:
        print('Something wrong with the video.')
        break
    if ret == True:
#         cv2.imshow('frame',frame)
        frame = cv2.resize(frame,(1320,810))
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)#记忆：BGR to GRAY
        cv2.imshow('result', gray)
        if cv2.waitKey(15) & 0xFF == 27:#括号中为帧间隔
            break
vc.release()
cv2.destroyAllWindows()
import cv2
def cv_show(name, img):
    cv2.imshow('image', img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()#再次定义cv_show函数
img = cv2.imread('cat.png')
cat = img[0:200,0:200]
cv_show('ROI cat', cat)#Region Of Interest 感兴趣的区域（截图）
颜色通道提取
b,g,r = cv2.split(img)
b
array([[125, 140, 146, ..., 151, 149, 153],
       [ 67, 116, 109, ..., 165, 163, 162],
       [ 89, 109, 107, ..., 166, 167, 164],
       ...,
       [ 82, 127, 154, ..., 152, 175, 198],
       [170, 173, 150, ..., 197, 193, 194],
       [133, 153, 151, ..., 190, 175, 131]], dtype=uint8)
b.shape
(413, 499)
img = cv2.merge((b,g,r))#颜色通道组合
# cv2.imshow('image',img)
# cv2.waitKey(0)
# cv2.destroyAllWindows()
img.shape
(413, 499, 3)
cur_img = img.copy()#深拷贝原图片
cur_img[:,:,0] = 0#B通道赋值0
cur_img[:,:,1] = 0#G通道赋值0
cv_show('R',cur_img)
边界填充
top_size,bottom_size,left_size,right_size = [50,50,50,50]

img = cv2.imread('cat.png', cv2.IMREAD_GRAYSCALE)
# img = cv2.resize(img,(300,450))
img.shape
replicate = cv2.copyMakeBorder(img,top_size,bottom_size,left_size,right_size,cv2.BORDER_REPLICATE)#复制法，利用最边缘像素复制填充
reflect = cv2.copyMakeBorder(img,top_size,bottom_size,left_size,right_size,cv2.BORDER_REFLECT)#镜像法，edcba|abcdefgh|hgfed
reflect_101 = cv2.copyMakeBorder(img,top_size,bottom_size,left_size,right_size,cv2.BORDER_REFLECT_101)#镜像法改，fedcb|abcdefgh|gfedc
wrap = cv2.copyMakeBorder(img,top_size,bottom_size,left_size,right_size,cv2.BORDER_WRAP)#外包装法defgh|abcdefgh|abcde
constant = cv2.copyMakeBorder(img,top_size,bottom_size,left_size,right_size,cv2.BORDER_CONSTANT,value = 0)#赋值法，边缘赋颜色值，需要指出value = ()
cv_show('img1', reflect_101)
数值计算
img_cat = cv2.imread('cat.png')
img_dog = cv2.imread('dog.png')
img_cat2 = img_cat + 10
img_cat[:5,:,0]#前5行，所有列，0通道
array([[125, 140, 146, ..., 151, 149, 153],
       [ 67, 116, 109, ..., 165, 163, 162],
       [ 89, 109, 107, ..., 166, 167, 164],
       [120, 151, 159, ..., 166, 164, 166],
       [140, 175, 171, ..., 166, 164, 167]], dtype=uint8)
img_cat2[:5,:,0]#超出256的部分除256取余
array([[135, 150, 156, ..., 161, 159, 163],
       [ 77, 126, 119, ..., 175, 173, 172],
       [ 99, 119, 117, ..., 176, 177, 174],
       [130, 161, 169, ..., 176, 174, 176],
       [150, 185, 181, ..., 176, 174, 177]], dtype=uint8)
(img_cat + img_cat2)[:5,:,0]#超出256的部分除256取余
array([[  4,  34,  46, ...,  56,  52,  60],
       [144, 242, 228, ...,  84,  80,  78],
       [188, 228, 224, ...,  86,  88,  82],
       [250,  56,  72, ...,  86,  82,  86],
       [ 34, 104,  96, ...,  86,  82,  88]], dtype=uint8)
cv2.add(img_cat,img_cat2)[:5,:,0]#超出255的部分直接取255
array([[255, 255, 255, ..., 255, 255, 255],
       [144, 242, 228, ..., 255, 255, 255],
       [188, 228, 224, ..., 255, 255, 255],
       [250, 255, 255, ..., 255, 255, 255],
       [255, 255, 255, ..., 255, 255, 255]], dtype=uint8)
img_cat + img_dog
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
Cell In[16], line 1
----> 1 img_cat + img_dog

ValueError: operands could not be broadcast together with shapes (413,499,3) (417,488,3) 
img_dog = cv2.resize(img_dog,(499,413))#简单的换形函数
cv_show('image_1',img_dog)
cv_show('image_2',img_cat)
img_dog.shape
(img_cat + img_dog)[:5,:,0]
array([[ 40,  66,  58, ...,  91,  91,  95],
       [245,  49,  29, ..., 105, 104, 102],
       [ 17,  45,  35, ..., 103, 105, 101],
       [ 48,  87,  91, ..., 100,  99, 101],
       [ 61, 111, 103, ..., 100,  99, 101]], dtype=uint8)
res = cv2.resize(img_dog,(0,0),fx=1,fy=1)#倍数换形函数
plt.imshow(res)
cv_show('img',img_dog)

图层叠加
res = cv2.addWeighted(img_cat,0.4,img_dog,0.6,0)#(img_a,虚化倍数,img_b,虚化倍数,提亮权重)，R=αA+βB+C
cv_show('img',res)
plt.imshow(res)
<matplotlib.image.AxesImage at 0x14f5d3d3510>

图像阈值
ret , dst = cv2.threshold(src , thresh , maxval , type)<灰度图像 ，最低阈值 ， 最高阈值 ， 二值化处理类型>

# cv2.THRESH_BINARY    超过阈值部分取最大值（maxval），否则取0
# cv2.THRESH_BINARY_INV小于阈值部分取最大值（maxval），否则取0
# cv2.THRESH_TRUNC     大于阈值部分取截断值（thresh），其余不变
# cv2.THRESH_TOZERO    大于阈值部分不改变，否则取0
# cv2.THRESH_TOZERO_INV小于阈值部分不改变，否则取0
import cv2
import numpy as mp
import matplotlib.pyplot as plt


def cv_show(name,img):
    cv2.imshow('image',img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    

# img_gray = cv2.imread('cat_png',cv2.IMREAD_GRAYSCALE)
# cv_show('image',img_gray)
img = cv2.imread('cat.png')
img_gray = cv2.imread('cat.png',cv2.IMREAD_GRAYSCALE)
cv_show('12',img_gray)


ret , draft_1 = cv2.threshold(img_gray , 127 , 256 , cv2.THRESH_BINARY)
ret , draft_2 = cv2.threshold(img_gray , 127 , 256 , cv2.THRESH_BINARY_INV)
ret , draft_3 = cv2.threshold(img_gray , 127 , 256 , cv2.THRESH_TRUNC)
ret , draft_4 = cv2.threshold(img_gray , 127 , 256 , cv2.THRESH_TOZERO)
ret , draft_5 = cv2.threshold(img_gray , 127 , 256 , cv2.THRESH_TOZERO_INV)


titles = ['origin' , 'BINARY' , 'BINARY_INV' , 'TURNC' , 'TOZERO' , 'TOZERO_INV']
images = [img , draft_1 , draft_2 , draft_3 , draft_4 , draft_5]

for i in range(6):
    plt.subplot(2 , 3 , i+1) , plt.imshow(images[i],'gray')
    plt.title(titles[i])
    plt.xticks([]) , plt.yticks([])
plt.show()
img.shape

(413, 499, 3)
图像平滑处理
img = cv2.imread('lenanoise.png')
cv_show('12',img)
均值滤波：简单的平均卷积操作
img = cv2.imread('lenanoise.png')
cv_show('12',img)
lenanoise_blur = cv2.blur(img,(3,3))
cv_show('12',lenanoise_blur)
titles = ['origin' , 'blur']
images = [img , lenanoise_blur]

# for i in range(2):
#     plt.subplot(2 , 3 , i+1) , plt.imshow(images[i])
#     plt.title(titles[i])
#     plt.xticks([]) , plt.yticks([])
# plt.show()
方框滤波：基本和均值一样，但可以选择归一化
# -1：得到的结果和输入图片的颜色通道数一致
# normalize = True/False : 是否做归一化。做归一化结果和均值滤波相同。
# **归一化**
lenanoise_box_1 = cv2.boxFilter(img , -1 , (3 , 3) , normalize = True)
cv_show('12',lenanoise_box_1)
# **不归一化**
# 大于255的越界值均取255
lenanoise_box_2 = cv2.boxFilter(img , -1 , (3 , 3) , normalize = False)
cv_show('12',lenanoise_box_2)
高斯滤波：按统计学中的高斯分布函数对离中心点远近不同的像素点进行加权平均处理
lenanoise_gaussian = cv2.GaussianBlur(img , (5 ,5) , 1)
cv_show('12' , lenanoise_gaussian)
中值滤波：取矩阵中所有值按大小排序后的中值为平滑处理结果
lenanoise_median = cv2.medianBlur(img , 5)
cv_show('12' , lenanoise_median)
均值|高斯|中值比较
import numpy as np
res = np.hstack((lenanoise_blur , lenanoise_gaussian , lenanoise_median))
cv2.imshow('blur|gaussian|median' , res)
cv2.waitKey(0)
cv2.destroyAllWindows()
Week 2
腐蚀操作<一般采用二值数据图像>
import cv2
import numpy as np
import matplotlib.pyplot as plt
img = cv2.imread('dige.png')
def cv_show(name,img):
    cv2.imshow('',img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
cv_show('1',img)
kernel = np.ones((3,3),np.uint8)#确定腐蚀矩阵大小
erosion = cv2.erode(img,kernel,iterations = 1)#一次迭代腐蚀
erosion_1 = cv2.erode(img,kernel,iterations = 2)#两次迭代腐蚀
cv_show('1',img)
cv2.imwrite('dige_erosion_3_1.png',erosion)
# res = np.hstack((img,erosion,erosion_1))
# cv_show('res',res)
True
img = cv2.imread('pie.png')
cv_show('1',img)
kernel = np.ones((30,30),np.uint8)
erosion_1 = cv2.erode(img,kernel,iterations = 1)
erosion_2 = cv2.erode(img,kernel,iterations = 2)
erosion_3 = cv2.erode(img,kernel,iterations = 3)
res = np.hstack((erosion_1,erosion_2,erosion_3))
cv_show('1',res)
膨胀操作
img = cv2.imread('pie.png')
cv_show('1',img)
kernel = np.ones((30,30),np.uint8)
pie_dilate = cv2.dilate(img,kernel,iterations = 3)
cv_show('1',pie_dilate)
# img_1 = cv2.imread('pie.png')
# res = np.hstack((img_1,img,pie_dilate))
# cv_show('1',res)
开运算和闭运算
开运算：先腐蚀再膨胀
img = cv2.imread('dige.png')

kernel = np.ones((3,3),np.uint8)
opening = cv2.morphologyEx(img,cv2.MORPH_OPEN,kernel)

cv_show('1',opening)
闭运算：先膨胀再腐蚀
img = cv2.imread('dige.png')

kernel = np.ones((3,3),np.uint8)
closing = cv2.morphologyEx(img,cv2.MORPH_CLOSE,kernel)

cv_show('1',closing)
**要根据实际情况挑选，降噪一般选用开运算。**
梯度运算
img = cv2.imread('pie.png')

kernel = np.ones((30,30),np.uint8)
erosion = cv2.erode(img,kernel,iterations = 3)
dilate = cv2.dilate(img,kernel,iterations = 3)
res = np.hstack((img,erosion,dilate))

cv_show('res',res)
## 展示膨胀和腐蚀的边缘差距
gradiant = cv2.morphologyEx(img,cv2.MORPH_GRADIENT,kernel)#直接应用梯度函数计算边缘差距

cv_show('1',gradiant)
礼帽与黑帽

黑帽 = 闭运算结果 - 原始输入
礼帽 = 原始输入 - 开运算结果
img = cv2.imread('dige.png')
kernel = np.ones((3,3),np.uint8)

tophat = cv2.morphologyEx(img,cv2.MORPH_TOPHAT,kernel)

cv_show('1',tophat)
#礼帽运算得到的是去除掉的毛刺
img = cv2.imread('dige.png')
kernel = np.ones((7,7),np.uint8)

blackhat = cv2.morphologyEx(img,cv2.MORPH_BLACKHAT,kernel)

cv_show('1',blackhat)
#黑帽运算得到的是处理后图片的边缘
图像梯度—Sobel算子

Gx = 右 - 左
Gy = 下 - 上
image.png

dst = cv2.Sobel(src,ddepth,dx,dy,ksize)

ddepth:图像的深度
dx和dy分别表示水平和竖直方向
ksize表示Sobel算子的大小
img = cv2.imread('pie.png')

#sobel_x = cv2.Sobel(img,cv2.CV_64F,1,0,ksize = 3)#表示只计算x方向的梯度
## **此处和教程不同，教程得出的是半圆，我得出半圆的方法下附。**
sobel_x = cv2.Sobel(img,cv2.-1,1,0,ksize = 3)
cv_show('sobel_x',sobel_x)

# top_size,bottom_size,left_size,right_size = [32,32,0,0]

# constant = cv2.copyMakeBorder(img,top_size,bottom_size,left_size,right_size,cv2.BORDER_CONSTANT,value = 0)#赋值法，边缘赋颜色值，需要指出value = ()
# cv_show('img1', constant)
# constant.shape
# cv2.imwrite('pie.png',constant)
得出图像为半圆的原因：

黑色为0，白色为255。
左半部分为白 - 黑，得出255，边界白色。
左半部分为黑 - 白，得出-255取0，边界黑色。
sobel_x = cv2.Sobel(img,cv2.CV_64F,1,0,ksize = 3)#表示只计算x方向的梯度
sobel_x = cv2.convertScaleAbs(sobel_x)
cv_show('sobel_x',sobel_x)
sobel_y = cv2.Sobel(img,cv2.CV_64F,0,1,ksize = 3)#表示只计算y方向的梯度
sobel_y = cv2.convertScaleAbs(sobel_y)
cv_show('sobel_y',sobel_y)
分别计算x和y，再求和

sobel_xy = cv2.addWeighted(sobel_x,0.5,sobel_y,0.5,0)
sobel_xy = cv2.convertScaleAbs(sobel_xy)
cv_show('sobel_xy',sobel_xy)
不建议直接求和

sobel_xy = cv2.Sobel(img,cv2.CV_64F,1,1,ksize = 3)
sobel_xy = cv2.convertScaleAbs(sobel_xy)
cv_show('sobel_xy',sobel_xy)
对lenanoise图片进行边缘处理（梯度运算）

import cv2
import numpy as np
import matplotlib.pyplot as plt

def cv_show(name,img):
    cv2.imshow('',img)
    cv2.waitKey()
    cv2.destroyAllWindows()

img_1 = cv2.imread('lenanoise.png',cv2.IMREAD_GRAYSCALE)
lenanoise_median = cv2.medianBlur(img_1 , 5)
# cv_show('12' , lenanoise_median)
cv2.imwrite('lenanoise_median.png',lenanoise_median)

img_2 = cv2.imread('lenanoise_median.png',cv2.IMREAD_GRAYSCALE)

sobel_x = cv2.Sobel(img,cv2.CV_64F,1,0,ksize = 3)
sobel_x = cv2.convertScaleAbs(sobel_x)
sobel_y = cv2.Sobel(img,cv2.CV_64F,0,1,ksize = 3)
sobel_y = cv2.convertScaleAbs(sobel_y)

sobel_xy = cv2.addWeighted(sobel_x,0.5,sobel_y,0.5,0)
# sobel_xy = cv2.convertScaleAbs(sobel_xy)

cv_show('lenanoise_gradiant',sobel_xy)

res = np.hstack((img_1,img_2,sobel_xy))
cv_show('res',res)
Scharr算子和laplacian算子 image-2.png <注：Scharr算子的Gy第三行应为正数。>

不同算子的差异：

img = cv2.imread('lena.jpg',cv2.IMREAD_GRAYSCALE)
cv_show('',img)

sobel_x = cv2.Sobel(img,cv2.CV_64F,1,0,ksize = 3)
sobel_y = cv2.Sobel(img,cv2.CV_64F,0,1,ksize = 3)
cv2.convertScaleAbs(sobel_x)
cv2.convertScaleAbs(sobel_y)
sobel_xy = cv2.addWeighted(sobel_x,0.5,sobel_y,0.5,0)
sobel_xy = cv2.convertScaleAbs(sobel_xy)

scharr_x = cv2.Scharr(img,cv2.CV_64F,1,0)
scharr_y = cv2.Scharr(img,cv2.CV_64F,0,1)
cv2.convertScaleAbs(scharr_x)
cv2.convertScaleAbs(scharr_y)
scharr_xy = cv2.addWeighted(scharr_x,0.5,scharr_y,0.5,0)
scharr_xy = cv2.convertScaleAbs(scharr_xy)

laplacian = cv2.Laplacian(img,cv2.CV_64F)
laplacian = cv2.convertScaleAbs(laplacian)

# titles = ['Sobel','Scharr','Laplacian']
# images = [sobel_xy,scharr_xy,laplacian]
# for i in range(3):
#     plt.subplot(2 , 3 , i+1) , plt.imshow(images[i],'gray')
#     plt.title(titles[i])
#     plt.xticks([]) , plt.yticks([])
# plt.show()

res = np.hstack((sobel_xy,scharr_xy,laplacian))
cv_show('res',res)
Canny边缘检测
流程： 高斯滤波-->像素点梯度强度和方向计算-->非极大值抑制(NMS)-->双阈值(Double Threshold)检测-->边缘检测

import cv2
import numpy as np
import matplotlib.pyplot as plt

#Canny边缘检测
img = cv2.imread('lena.jpg',cv2.IMREAD_GRAYSCALE)

v1 = cv2.Canny(img,80,150)#(双阈值定义1：minVal = 80，maxVal = 150)
v2 = cv2.Canny(img,50,100)#(双阈值定义1：minVal = 50，maxVal = 100)

res = np.hstack((v1,v2))

def cv_show(name,img):
    cv2.imshow('',img)
    cv2.waitKey()
    cv2.destroyAllWindows()
    
cv_show('res',res)
QQ%E5%9B%BE%E7%89%8720240117164535.png

图像金字塔
高斯金字塔
拉普拉斯金字塔
<向下采样：塔底向塔尖方向|向上采样：塔尖向塔底方向>
img = cv2.imread('AM.png')
cv_show('img',img)
# print(img.shape)

up = cv2.pyrUp(img)
cv_show('up',up)
# print(up.shape)

down = cv2.pyrDown(img)
cv_show('down',down)
print(down.shape)
(221, 170, 3)
up1 = cv2.pyrUp(img)
up_down = down = cv2.pyrDown(up1)
res = np.hstack((up_down,img))
cv_show('',res)
经过两次采样（高斯金字塔）变换后的图片对比

image.png

拉普拉斯金字塔：计算原图和up_down图像的差值

up1 = cv2.pyrUp(img)
up_down =  cv2.pyrDown(up1)
res = img - up_down
cv_show('res',res)
image.png

Week 3
cv2.findContours(img,mode,method)

mode:轮廓检索模式（常用第四种）

RETR_EXTERNAL:检索最外面的轮廓
RETR_LIST:检索所有的轮廓，并将它们保存在同一条链表当中
RETR_CCOMP:检索所有的轮廓，并将它们组织为两层：顶层是各部分的外部边界，第二层是空洞的边界
RETR_TREE:检索所有的轮廓，并重构嵌套轮廓的整个层次
method:轮廓逼近方法

CHAIN_APPROX_NONE：以Freeman链码的方式输出轮廓，所有其他方法输出多边形（顶点的序列）
CHAIN_APPROX_SIMPLE:压缩水平的、垂直的和斜的部分，也就是，函数只保留他们的终点部分
import cv2
import matplotlib.pyplot as plt
import numpy as np

def cv_show(name,img):
    cv2.imshow('image',img)
    cv2.waitKey()
    cv2.destroyAllWindows()

img = cv2.imread('contours.png')
# cv_show('',img)
gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
ret , thresh = cv2.threshold(gray , 127 , 255 , cv2.THRESH_BINARY)#(二值化处理，以获得更高的准确率)
res = np.hstack((gray,thresh))
cv_show('thresh',thresh)
# 先对图像进行适当处理

contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)# 这一步返回了轮廓和轮廓层级等信息，便于后续绘画
绘制图像轮廓

注意：绘制图像时要对图像的拷贝文件进行操作，否则描绘的图像轮廓会直接绘制在原图上。
cv_show('',img)
draw_img = img.copy()# 深拷贝，复制一张新的img用于轮廓绘制
res = cv2.drawContours(draw_img,contours,-1,(0,255,0),2)# （处理图像，边界，边界索引，线条颜色，线条厚度）
# 边界索引指定-1时为全部边界，指定正数时为依次选择任一个轮廓的内外边界。
# cv_show('res',res)
show = np.hstack((img,res))
cv_show('',show)
绘制轮廓前后对比

image.png

轮廓特征
轮廓面积
轮廓周长
轮廓近似
# 计算轮廓面积时需选择轮廓列表中任一个封闭图形的面积。
cnt = contours[0]
cv2.contourArea(cnt)
8500.5
# 周长，True表示闭合的。
cv2.arcLength(cnt,True)
437.9482651948929
轮廓近似

# 绘制外轮廓
img = cv2.imread('contours2.png')

gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
ret,thresh = cv2.threshold(gray,127,255,cv2.THRESH_BINARY)
contours,hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)

cnt = contours[0]
draw_img = img.copy()
res = cv2.drawContours(draw_img,contours,0,(0,255,0),2)
cv_show('res',res)
epsilon = 0.1*cv2.arcLength(cnt,True)# 设置控制参数精度，即曲线最远点距离阈值
approx = cv2.approxPolyDP(cnt,epsilon,True)

draw_img = img.copy()
res = cv2.drawContours(draw_img,[approx],-1,(0,255,0),2)# approx需要加中括号
cv_show('',res)
外接矩形/圆

# 外接矩形
img = cv2.imread('contours.png')

gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
ret,thresh = cv2.threshold(gray,127,255,cv2.THRESH_BINARY)
contours,hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)
cnt = contours[0]

x,y,w,h = cv2.boundingRect(cnt)# x,y:起始坐标 w,h:width&height
img = cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),1)
cv_show('',img)
area = cv2.contourArea(cnt)
x, y, w, h = cv2.boundingRect(cnt)
rect_area = w * h
extent = float(area) / rect_area
print ('轮廓面积与边界矩形比 =',extent)
轮廓面积与边界矩形比 = 0.7732441471571906
# 外接圆
(x,y),radius = cv2.minEnclosingCircle(cnt)# x,y,r
center = (int(x),int(y)) 
radius = int(radius) 
img = cv2.circle(img,center,radius,(0,255,0),1)
cv_show('',img)
模板匹配
模板匹配和卷积原理很像，模板在原图像上从原点开始滑动，计算模板与图像被模板覆盖的地方)的差别程度，这个差别程度的计算方法在opencv里有6种，然后将每次计算的结果放入一个矩阵里，作为结果输出。假如原图形是AxB大小，而模板是axb大小，则输出结果的矩阵是(A-a+1)x(B-b+1)

img = cv2.imread('lena.jpg',0)# 0代表将原图处理为灰度图
template = cv2.imread('face.jpg',0)
h,w = template.shape[:2]
img.shape
(263, 263)
template.shape
(110, 85)
TM_SQDIFF: 计算平方差不同，计算出来的值越小，越相关。
TM_CCORR:计算相关性，计算出来的值越大，越相关。
TM_CCOEFF:计算相关系数，计算出来的值越大，越相关。
TM_SQDIFF_NORMED: 计算归一化平方差不同，计算出来的值越接近0，越相关。
TM_CCORR_NORMED: 计算归一化相关性，计算出来的值越接近1，越相关。
TM_CCOEFF_NORMED: 计算归一化相关系数，计算出来的值越接近1，越相关。
res = cv2.matchTemplate(img,template,cv2.TM_SQDIFF)
res.shape
(154, 179)
min_val,max_val,min_loc,max_loc = cv2.minMaxLoc(res)
# 由于采用的是SQIDFF方法，值越小越相关，随后我们采用寻找最小值点的方法。
# 建议采用归一化方法，相对更可靠。
print(min_val,'|',max_val,'|',min_loc,'|',max_loc)
39168.0 | 74403584.0 | (107, 89) | (159, 62)
methods = ['cv2.TM_SQDIFF','cv2.TM_SQDIFF_NORMED','cv2.TM_CCORR','cv2.TM_CCORR_NORMED','cv2.TM_CCOEFF','cv2.TM_CCOEFF_NORMED']

for meth in methods:
    img2 = img.copy()
    
    #返回每种匹配方法代表字符串的真值（eval函数）
    method = eval(meth)
    print(method)
    res = cv2.matchTemplate(img,template,method)
    min_val,max_val,min_loc,max_loc = cv2.minMaxLoc(res)
    
    # 如果是SQIDFF（平方差）或者是SQIDFF_NORMED（归一化平方差），取最小值；其余方法都取最大值。
    if method in [cv2.TM_SQDIFF,cv2.TM_SQDIFF_NORMED]:
        top_left = min_loc
    else:
        top_left = max_loc
    bottom_right = (top_left[0]+w,top_left[1]+h)
    
    #绘制匹配矩形
    cv2.rectangle(img2,top_left,bottom_right,255,1)
    plt.subplot(121),plt.imshow(res,cmap='gray')
    plt.xticks([]),plt.yticks([]) # 隐藏坐标轴
    plt.subplot(122),plt.imshow(img2, cmap='gray')
    plt.xticks([]), plt.yticks([])
    plt.suptitle(meth)
    plt.show()
0

1

2

3

4

5

多对象匹配处理

img = cv2.imread('mario.jpg')
img_rgb = img.copy()
img_gray = cv2.cvtColor(img_rgb,cv2.COLOR_BGR2GRAY)
template = cv2.imread('mario_coin.jpg',0)
h,w = template.shape[:2]

res = cv2.matchTemplate(img_gray,template,cv2.TM_CCOEFF_NORMED)# 此方法计算值越接近1越相关
threshold = 0.8# 设置0.8为匹配阈值

loc = np.where(res >= threshold)
for pt in zip(*loc[::-1]):# 从最后一项开始遍历已列出的loc坐标
    bottom_right = (pt[0]+w,pt[1]+h)
    cv2.rectangle(img_rgb,pt,bottom_right,(0,255,0),1)
    
res = np.hstack((img,img_rgb))
cv_show('',res)
image.png

cv2.calcHist(images,channels,mask,histSize,ranges)
images: 原图像图像格式为 uint8 或 ﬂoat32。当传入函数时应用中括号[]括进来例如[img]。
channels: 同样用中括号括进来它会告函数我们统计幅图像的直方图。如果输入图像是灰度图它的值就是[0]如果是彩色图像的传入的参数可以是 [0][1][2] 它们分别对应着BGR。
mask: 掩模图像。统计整幅图像的直方图就把它设为None。但是如果你想统计图像某一部分的直方图的你就制作一个掩模图像并使用它。
histSize:BIN的数目。也应用中括号括进来。
ranges: 像素值范围常为 [0-256]
img = cv2.imread('cat.png',0)
hist = cv2.calcHist([img],[0],None,[256],[0,256])
hist.shape
(256, 1)
plt.hist(img.ravel(),256);
plt.show()

img = cv2.imread('cat.png')
color = ('b','g','r')
for i,col in enumerate(color):# 对颜色进行枚举遍历
    histr = cv2.calcHist([img],[i],None,[256],[0,256])
    plt.plot(histr,color = col)
    plt.xlim([0,256])

# 创建mask
mask = np.zeros(img.shape[:2], np.uint8)# 创建mask，和img尺寸相同
# print(mask.shape)
mask[100:300, 100:400] = 255# 创建蒙版
cv_show('mask',mask)
img = cv2.imread('cat.png',0)
# cv_show('',img)
# b,g,r = cv2.split(img)
# img = cv2.merge([r,g,b])

masked_img = cv2.bitwise_and(img,img,mask=mask)#与操作，将掩膜套到原图上
# cv_show('',masked_img)

hist_full = cv2.calcHist([img],[0],None,[256],[0, 256])
hist_mask = cv2.calcHist([img],[0],mask,[256],[0, 256])

plt.subplot(221),plt.imshow(img,'gray')
plt.subplot(222),plt.imshow(mask,'gray')
plt.subplot(223),plt.imshow(masked_img,'gray')
plt.subplot(224),plt.plot(hist_full),plt.plot(hist_mask)
plt.xlim([0, 256])
plt.show()

直方图均衡化
img = cv2.imread('cat.png',0)
plt.hist(img.ravel(),256)
plt.show()

equ = cv2.equalizeHist(img)
plt.hist(equ.ravel(),256)
plt.show()

res = np.hstack((img,equ))
cv_show('',res)
image.png

img = cv2.imread('lena.jpg',0)
equ = cv2.equalizeHist(img)
res = np.hstack((img,equ))
cv_show('',res)
image.png

img = cv2.imread('clahe.jpg',0)
equ = cv2.equalizeHist(img)
res = np.hstack((img,equ))
cv_show('',res)
image.png

亮度拉高，整体均衡化之后部分丢失细节（脸）

自适应直方图均衡化
clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8)) 
# clipLimit：对比度限制，超过设定对比度的像素将被截断。tileGridSize：切割出每个小块的大小。

res_clahe = clahe.apply(img)# 创造clahe对象后应用clahe.apply()可直接对图像进行均衡化。
res = np.hstack((img,equ,res_clahe))
cv_show('',res)
image.png

傅里叶变换
image.png

傅里叶变换的作用
高频：变化剧烈的灰度分量，例如边界

低频：变化缓慢的灰度分量，例如一片大海

滤波
低通滤波器：只保留低频，会使得图像模糊

高通滤波器：只保留高频，会使得图像细节增强

opencv中主要就是cv2.dft()和cv2.idft()，输入图像需要先转换成np.float32 格式。
得到的结果中频率为0的部分会在左上角，通常要转换到中心位置，可以通过shift变换来实现。
cv2.dft()返回的结果是双通道的（实部，虚部），通常还需要转换成图像格式才能展示（0,255）。
注：
dst = cv2.dft (src , flags)

src：输入图像，需要转换格式为np.float32，可以为实数矩阵或者复数矩阵

flags：转换标志

（如DFT_COMPLEX_OUTPUT，对一维或二维实数数组正变换，输出一个同样尺寸的复数矩阵）
（DFT_REAL_OUTPUT，对一维或二维复数数组反变换，通常输出同样尺寸的复矩阵）
返回结果：是双通道的，第一个的结果是虚数部分，第二个通道的结果是实数部分
np.fft.fftshift(dst)：将图像的低频部分移动到图像的中心

import numpy as np
import cv2
import matplotlib.pyplot as plt

img = cv2.imread('lena.jpg',0)
img_float32 = np.float32(img)

dft = cv2.dft(img_float32, flags = cv2.DFT_COMPLEX_OUTPUT)
dft_shift = np.fft.fftshift(dft)
# 得到灰度图能表示的形式

magnitude_spectrum = 20*np.log(cv2.magnitude(dft_shift[:,:,0],dft_shift[:,:,1]))

plt.subplot(221),plt.imshow(img,cmap='gray')
plt.title('Input'),plt.xticks([]),plt.yticks([])
plt.subplot(222),plt.imshow(magnitude_spectrum,cmap='gray')
plt.title('Magnitude Spectrum'),plt.xticks([]),plt.yticks([])
plt.show()

低通滤波处理：图像变得模糊

import numpy as np
import cv2
import matplotlib.pyplot as plt

img = cv2.imread('lena.jpg',0)
img_float32 = np.float32(img)

dft = cv2.dft(img_float32, flags = cv2.DFT_COMPLEX_OUTPUT)
dft_shift = np.fft.fftshift(dft)

# 定义掩膜
rows,cols = img.shape
crow,ccol = int(rows/2),int(cols/2)

mask = np.zeros((rows,cols,2),np.uint8)
mask[crow-30:crow+30,ccol-30:ccol+30] = 1

#IDFT
fshift = dft_shift*mask
f_ishift = np.fft.ifftshift(fshift)
img_back = cv2.idft(f_ishift)
img_back = cv2.magnitude(img_back[:,:,0],img_back[:,:,1])

plt.subplot(121),plt.imshow(img,cmap='gray')
plt.title('Input'),plt.xticks([]),plt.yticks([])
plt.subplot(122),plt.imshow(img_back,cmap='gray')
plt.title('Return'),plt.xticks([]),plt.yticks([])
plt.show()

高通滤波处理：保留边界

import numpy as np
import cv2
import matplotlib.pyplot as plt

img = cv2.imread('lena.jpg',0)
img_float32 = np.float32(img)

dft = cv2.dft(img_float32, flags = cv2.DFT_COMPLEX_OUTPUT)
dft_shift = np.fft.fftshift(dft)

# 定义掩膜
rows,cols = img.shape
crow,ccol = int(rows/2),int(cols/2)

mask = np.ones((rows,cols,2),np.uint8)
mask[crow-30:crow+30,ccol-30:ccol+30] = 0

#IDFT
fshift = dft_shift*mask
f_ishift = np.fft.ifftshift(fshift)
img_back = cv2.idft(f_ishift)
img_back = cv2.magnitude(img_back[:,:,0],img_back[:,:,1])

plt.subplot(121),plt.imshow(img,cmap='gray')
plt.title('Input'),plt.xticks([]),plt.yticks([])
plt.subplot(122),plt.imshow(img_back,cmap='gray')
plt.title('Return'),plt.xticks([]),plt.yticks([])
plt.show()

 
